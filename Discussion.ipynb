{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ea2ce8-a5f4-4e3a-a1f4-e578b3abfd3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Discussion\n",
    "* summarize what you found\n",
    "* discuss whether this is what you expected to find?\n",
    "* discuss what impact could such findings have?\n",
    "* discuss what future questions could this lead to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610ee999-a850-4f49-86a5-313fd2aa22e8",
   "metadata": {},
   "source": [
    "## Summarize\n",
    "To summarize, from an estimated accuracy versus the neighbour's plot(Fig 1.1), we know that the accuracy peaks when K is set to 16. This suggests that K = 16 is the optimal number of neighbours for the model on this particular dataset. When K is set to 16, we get approximately 64.8% accuracy. \n",
    "\n",
    "The confusion matrix shows the performance of a classification model (Fig 1.2). The rows represent the actual classes, and the columns represent the predicted classes. Therefore, the diagonal values are correctly guessed values. By inspecting the diagonal values, we can summarize that our classifier is very good at predicting the absence of heart disease (When Diagnosis is equal to zero). However, it is poor at predicting the presence of a diagnosis, especially when the diagnosis equals four. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86158a8a-23c6-47b8-bdaa-22ff73119a0a",
   "metadata": {},
   "source": [
    "## Expected Findings\n",
    "Expected\n",
    "For the confusion matrix, we were expecting the diagonal values (correct guesses) to be ideally higher than the off-diagonal ones (incorrect guesses) because our estimated accuracy was about 65%. As expected, the diagonal values (correct guesses) turned out to be higher than the off-diagonal ones (incorrect guesses). Diagonal values add up to 134, and off-diagonal values add up to 102. \n",
    "\n",
    "Unexpected\n",
    "However, something we didn't expect was inconsistency in accuracy when predicting a diagnosis equal to four. Our classifier model shows consistent accuracy when predicting diagnosis equal to 0 to 3. However, it shows 0% accuracy when it comes to predicting diagnosis equal to 4. This was something very unexpected as we assumed that the classifier would show 65% estimated accuracy across the entire diagnosis (From 0 to 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac174c1-d379-40ea-80a9-57e423818576",
   "metadata": {},
   "source": [
    "## Impacts \n",
    "These findings have an impact on healthcare settings where fast and accurate diagnosis is critical. For example, the model's high accuracy in identifying the absence of heart disease could make it a valuable tool for quickly ruling out heart conditions. This allows medical staff members to allocate their time to the patients who are highly suspected to have a heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb4261-4996-4cf9-b9b0-a6e8e82d97e7",
   "metadata": {},
   "source": [
    "## Future Questions\n",
    "Q. If improved, can our model be used in the field to diagnose heart disease? \n",
    "\n",
    "Q. Is the performance consistent across different heart disease data?\n",
    "\n",
    "Q. What are the misclassified cases in the confusion matrix, and what may be casing these errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b6399-122b-471d-ba32-c8e18d5a2893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
